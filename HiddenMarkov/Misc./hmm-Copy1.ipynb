{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2f562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "'''\n",
    "Reading the input file and storing the \n",
    "values of the 3 columns of each row in\n",
    "a tuple: (<Word>, <POS_TAG>, <CHUNK_TAG>)\n",
    "'''\n",
    "f = open(\"train.txt\", \"r\")\n",
    "sentence_corpus = []\n",
    "sentence = []\n",
    "\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    if line == \"\":\n",
    "        sentence_corpus.append(sentence)\n",
    "        sentence = []\n",
    "    else:\n",
    "        word, pos_tag, _ = line.split(\" \")\n",
    "        #ignoring the chunk tag for this task\n",
    "        sentence.append((word, pos_tag))\n",
    "f.close()\n",
    "\n",
    "# Add the last sentence (if any)\n",
    "if sentence:\n",
    "    sentence_corpus.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8381cbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ('pound', 'NN'), ('is', 'VBZ'), ('widely', 'RB'), ('expected', 'VBN'), ('to', 'TO'), ('take', 'VB'), ('another', 'DT'), ('sharp', 'JJ'), ('dive', 'NN'), ('if', 'IN'), ('trade', 'NN'), ('figures', 'NNS'), ('for', 'IN'), ('September', 'NNP'), (',', ','), ('due', 'JJ'), ('for', 'IN'), ('release', 'NN'), ('tomorrow', 'NN'), (',', ','), ('fail', 'VB'), ('to', 'TO'), ('show', 'VB'), ('a', 'DT'), ('substantial', 'JJ'), ('improvement', 'NN'), ('from', 'IN'), ('July', 'NNP'), ('and', 'CC'), ('August', 'NNP'), (\"'s\", 'POS'), ('near-record', 'JJ'), ('deficits', 'NNS'), ('.', '.')], [('Chancellor', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Exchequer', 'NNP'), ('Nigel', 'NNP'), ('Lawson', 'NNP'), (\"'s\", 'POS'), ('restated', 'VBN'), ('commitment', 'NN'), ('to', 'TO'), ('a', 'DT'), ('firm', 'NN'), ('monetary', 'JJ'), ('policy', 'NN'), ('has', 'VBZ'), ('helped', 'VBN'), ('to', 'TO'), ('prevent', 'VB'), ('a', 'DT'), ('freefall', 'NN'), ('in', 'IN'), ('sterling', 'NN'), ('over', 'IN'), ('the', 'DT'), ('past', 'JJ'), ('week', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print(sentence_corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5196147b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFirst implementation: Vertebi Algorithm from scratch\\nNote: Time consuming: Test data running for more than\\n      3 Hours.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "First implementation: Vertebi Algorithm from scratch\n",
    "Note: Time consuming: Test data running for more than\n",
    "      3 Hours.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9f75ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170288\n",
      "41439\n"
     ]
    }
   ],
   "source": [
    "#Splitting the corpus data into train_data and test_data (validadtion) (80/20 split)\n",
    "train_set,test_set =train_test_split(sentence_corpus,train_size=0.80,test_size=0.20,random_state = 101)\n",
    "\n",
    "# List of all the tags in the train and the test set (it may not be unique)\n",
    "train_tag_corpus = [ t for sentence in train_set for t in sentence ]\n",
    "test_tag_corpus = [ t for sentence in test_set for t in sentence ]\n",
    "print(len(train_tag_corpus))\n",
    "print(len(test_tag_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ac5e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Besides', 'IN'), ('sacking', 'VBG'), ('other', 'JJ'), ('senior', 'JJ'), ('Politburo', 'NNP'), ('officials', 'NNS'), ('who', 'WP'), ('allied', 'VBD'), ('themselves', 'PRP'), ('with', 'IN'), ('Mr.', 'NNP'), ('Honecker', 'NNP'), (',', ','), ('Mr.', 'NNP'), ('Krenz', 'NNP'), ('could', 'MD'), ('loosen', 'VB'), ('controls', 'NNS'), ('on', 'IN'), ('the', 'DT')]\n"
     ]
    }
   ],
   "source": [
    "print(train_tag_corpus[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa2dab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding number of unique tags and words (Vocabulary)\n",
    "train_tag_set = {tag for word, tag in train_tag_corpus}\n",
    "vocab = {word for word, tag in train_tag_corpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "584de74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods to compute transition and emission\n",
    "\n",
    "'''\n",
    "prev_tag -> current_tag \n",
    "Pr(current_tag | prev_tag) = (# of prev_tag -> current_tag)/(# of prev_tag)\n",
    "'''\n",
    "def computeTransition(prev_tag, current_tag):\n",
    "    tags = [tag for _, tag in train_tag_corpus]\n",
    "    \n",
    "    #Count of prev_tag\n",
    "    cnt_prev_tag = len([tag for tag in tags if tag == prev_tag])\n",
    "    cnt_prev_curr_tag = 0\n",
    "    \n",
    "    for i in range(1, len(tags)):\n",
    "        if tags[i-1] == prev_tag and tags[i] == current_tag:\n",
    "            cnt_prev_curr_tag += 1\n",
    "    \n",
    "    return cnt_prev_curr_tag / cnt_prev_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "240b5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The crux of HMM is the emission and transition probabilities\n",
    "\n",
    "#Transition\n",
    "transition = np.zeros((len(train_tag_set), len(train_tag_set)), dtype='float32')\n",
    "train_tag_list = list(train_tag_set)\n",
    "for i in range(len(train_tag_list)):\n",
    "    for j in range(len(train_tag_list)):\n",
    "        transition[i,j] = computeTransition(train_tag_list[i], train_tag_list[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e90365b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Emission Probability\n",
    "def computeEmission(word, tag):\n",
    "    train_bag = train_tag_corpus\n",
    "    tag_list = [tg for tg in train_bag if tg[1]==tag]\n",
    "    cnt_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    " \n",
    "    return count_w_given_tag / cnt_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "45a2c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission = {}\n",
    "# vocab_list = list(vocab)\n",
    "# for word in vocab_list:\n",
    "#     for tag in train_tag_list:\n",
    "#         if (word, tag) in emission.keys():\n",
    "#             continue\n",
    "#         else:\n",
    "#             emission[(word, tag)] = computeEmission(word, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e76d9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = pd.DataFrame(transition, columns = list(train_tag_list), index=list(train_tag_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37d7dfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f182781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import threading\n",
    "\n",
    "def viterbi_memoization_threaded(words):\n",
    "    train_bag = train_tag_corpus\n",
    "    tags = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    # initialize memoization dictionary\n",
    "    memo = {}\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    # initialize probability matrix\n",
    "    T = len(words)\n",
    "    prob_matrix = np.zeros((T, len(tags)))\n",
    "    \n",
    "    # fill in first column of probability matrix\n",
    "    for i, tag in enumerate(tags):\n",
    "        if (words[0], tag) in memo:\n",
    "            emission_p = memo[(words[0], tag)]\n",
    "        else:\n",
    "            emission_p = computeEmission(words[0], tag)[0] / word_given_tag(words[0], tag)[1]\n",
    "            memo[(words[0], tag)] = emission_p\n",
    "        prob_matrix[0][i] = tags_df.loc['.', tag] * emission_p\n",
    "        \n",
    "    # define worker function for multithreading\n",
    "    def worker(i, j, tag, tags):\n",
    "        max_prob = 0\n",
    "        for k, prev_tag in enumerate(tags):\n",
    "            transition_p = tags_df.loc[prev_tag, tag]\n",
    "            prob = prob_matrix[i-1][k] * transition_p\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                lock.acquire()\n",
    "                if (words[i], tag) in memo:\n",
    "                    emission_p = memo[(words[i], tag)]\n",
    "                else:\n",
    "                    emission_p = computeEmission(words[i], tag)[0] / word_given_tag(words[i], tag)[1]\n",
    "                    memo[(words[i], tag)] = emission_p\n",
    "                prob_matrix[i][j] = max_prob * emission_p\n",
    "                lock.release()\n",
    "    \n",
    "    # fill in remaining columns of probability matrix using multithreading\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for i in range(1, T):\n",
    "            for j, tag in enumerate(tags):\n",
    "                futures.append(executor.submit(worker, i, j, tag, tags))\n",
    "        concurrent.futures.wait(futures)\n",
    "    print(\"Aman\")\n",
    "    \n",
    "    print(prob_matrix)\n",
    "    # backtrack to find optimal sequence of tags\n",
    "    state = []\n",
    "    max_prob = max(prob_matrix[-1])\n",
    "    prev_tag = None\n",
    "    for i in range(T-1, -1, -1):\n",
    "        for j, tag in enumerate(tags):\n",
    "            if prob_matrix[i][j] == max_prob:\n",
    "                if prev_tag:\n",
    "                    state.insert(0, prev_tag)\n",
    "                max_prob /= memo[(words[i], tag)]\n",
    "                max_prob /= tags_df.loc[prev_tag, tag]\n",
    "                prev_tag = tag\n",
    "                break\n",
    "    \n",
    "    state.insert(0, prev_tag)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99ca5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def viterbi_parallel(words, train_bag=train_tag_corpus):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "\n",
    "    # create a lock\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # create list of tasks to be executed concurrently\n",
    "        tasks = []\n",
    "        for key, word in enumerate(words):\n",
    "            task = executor.submit(process_word, key, word, state, T, lock)\n",
    "            tasks.append(task)\n",
    "\n",
    "        # wait for tasks to complete and collect results\n",
    "        for task in concurrent.futures.as_completed(tasks):\n",
    "            result = task.result()\n",
    "            state = result[:]\n",
    "\n",
    "    return list(zip(words, state))\n",
    "\n",
    "def process_word(key, word, state, T, lock):\n",
    "    # acquire the lock\n",
    "    lock.acquire()\n",
    "\n",
    "    #initialise list of probability column for a given observation\n",
    "    p = []\n",
    "    for tag in T:\n",
    "        if key == 0:\n",
    "            transition_p = tags_df.loc['.', tag]\n",
    "        else:\n",
    "            transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "        # compute emission and state probabilities\n",
    "        emission_p = computeEmission(word, tag)[0]/word_given_tag(word, tag)[1]\n",
    "        state_probability = emission_p * transition_p\n",
    "        p.append(state_probability)\n",
    "\n",
    "    pmax = max(p)\n",
    "    # getting state for which probability is maximum\n",
    "    state_max = T[p.index(pmax)]\n",
    "\n",
    "    # append the state_max to the state list\n",
    "    state.append(state_max)\n",
    "\n",
    "    # release the lock\n",
    "    lock.release()\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "58454b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag = train_tag_corpus):\n",
    "    pos = []\n",
    "    dp = {}\n",
    "    tags = list(set([pair[1] for pair in train_bag]))\n",
    "     \n",
    "    for key, word in enumerate(words):\n",
    "        p = []\n",
    "        pmax = -float(\"inf\")\n",
    "        p_index = 0\n",
    "        for i, tag in enumerate(tags):\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[pos[-1], tag]\n",
    "            \n",
    "            if (tag, word) in dp.keys():\n",
    "                emission_p = dp[(tag, word)]\n",
    "            else:\n",
    "                emission_p = computeEmission(words[key], tag)\n",
    "                dp[(tag, word)] = emission_p\n",
    "                \n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            if state_probability > pmax:\n",
    "                pmax = state_probability\n",
    "                p_index = i\n",
    "             \n",
    "        #pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        pos_max = tags[p_index] \n",
    "        pos.append(pos_max)\n",
    "    return list(zip(words, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9a535b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rndom = [random.randint(1,len(test_set)) for x in range(10)]\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "14b20a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "# test_untagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "# #test_untagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "fbe672c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time =  109.052237033844\n",
      "Viterbi Algorithm Accuracy:  88.47736625514403\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "diff = end-start\n",
    "print(\"Time = \", diff)\n",
    "# print(tagged_seq[:10])\n",
    "# #accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    " \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)\n",
    "\n",
    " #Accuracy of random 10 sentences on the split test data set is 94% using Viterbi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "999ce7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSecond Implementation: Using NLTK's hmm\\nTakes less time and easier to impement\\n\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Second Implementation: Using NLTK's hmm\n",
    "Takes less time and easier to impement\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a312cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating HMM object\n",
    "HmmModel = nltk.HiddenMarkovModelTagger.train(train_set)\n",
    "\n",
    "true_pos_tags = [tag for sentences in test_run for word, tag in sentences]\n",
    "\n",
    "predicted_pos_tags=[]\n",
    "for sentences in test_run:\n",
    "    predicted_pos_tags += [tag for _, tag in HmmModel.tag([word for word, _ in sentences])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8232e784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           $       0.67      1.00      0.80         2\n",
      "          ''       0.00      0.00      0.00         0\n",
      "           ,       1.00      1.00      1.00        12\n",
      "           .       0.91      1.00      0.95        10\n",
      "          CC       1.00      1.00      1.00         9\n",
      "          CD       0.90      1.00      0.95         9\n",
      "          DT       0.95      1.00      0.98        21\n",
      "          EX       1.00      1.00      1.00         1\n",
      "          IN       1.00      1.00      1.00        24\n",
      "          JJ       0.94      0.89      0.91        18\n",
      "         JJR       1.00      1.00      1.00         1\n",
      "          MD       0.75      1.00      0.86         3\n",
      "          NN       0.97      0.92      0.95        39\n",
      "         NNP       0.93      1.00      0.97        14\n",
      "         NNS       1.00      0.83      0.91        18\n",
      "         POS       1.00      1.00      1.00         1\n",
      "         PRP       1.00      1.00      1.00         9\n",
      "        PRP$       1.00      1.00      1.00         2\n",
      "          RB       0.86      1.00      0.92         6\n",
      "          TO       1.00      1.00      1.00         9\n",
      "          VB       0.92      1.00      0.96        12\n",
      "         VBD       1.00      0.77      0.87        13\n",
      "         VBG       1.00      1.00      1.00         5\n",
      "         VBN       0.62      0.83      0.71         6\n",
      "         VBP       1.00      0.33      0.50         3\n",
      "         VBZ       1.00      1.00      1.00         4\n",
      "         WRB       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.94       252\n",
      "   macro avg       0.90      0.91      0.90       252\n",
      "weighted avg       0.96      0.94      0.95       252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "print (classification_report(true_pos_tags, predicted_pos_tags))\n",
    "#Accuracy of random 10 sentences on the split test data set is 95% using nltk's hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5d9e646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_tags = [tag for sentences in test_set for word, tag in sentences]\n",
    "\n",
    "predicted_pos_tags=[]\n",
    "for sentences in test_set:\n",
    "    predicted_pos_tags += [tag for _, tag in HmmModel.tag([word for word, _ in sentences])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2b093acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       1.00      1.00      1.00         6\n",
      "           $       0.81      1.00      0.90       311\n",
      "          ''       0.77      1.00      0.87       297\n",
      "           (       0.97      0.97      0.97        39\n",
      "           )       0.64      0.92      0.76        39\n",
      "           ,       0.98      1.00      0.99      2127\n",
      "           .       0.95      1.00      0.97      1767\n",
      "           :       0.99      0.99      0.99       203\n",
      "          CC       0.97      1.00      0.99      1054\n",
      "          CD       0.95      0.91      0.93      1599\n",
      "          DT       0.95      0.99      0.97      3576\n",
      "          EX       1.00      0.89      0.94        46\n",
      "          FW       1.00      0.10      0.18        10\n",
      "          IN       0.97      0.99      0.98      4399\n",
      "          JJ       0.90      0.86      0.88      2549\n",
      "         JJR       0.86      0.93      0.89       169\n",
      "         JJS       0.98      0.87      0.92        75\n",
      "          MD       0.92      1.00      0.96       376\n",
      "          NN       0.97      0.91      0.94      5942\n",
      "         NNP       0.94      0.92      0.93      3846\n",
      "        NNPS       0.91      0.52      0.67        82\n",
      "         NNS       0.93      0.89      0.91      2670\n",
      "         PDT       1.00      0.86      0.92         7\n",
      "         POS       0.88      0.97      0.93       350\n",
      "         PRP       0.87      0.99      0.93       759\n",
      "        PRP$       0.82      0.99      0.90       351\n",
      "          RB       0.91      0.91      0.91      1309\n",
      "         RBR       0.96      0.75      0.84        64\n",
      "         RBS       1.00      0.97      0.99        38\n",
      "          RP       0.00      0.00      0.00        16\n",
      "         SYM       0.00      0.00      0.00         1\n",
      "          TO       0.98      1.00      0.99      1050\n",
      "          UH       1.00      0.50      0.67         2\n",
      "          VB       0.89      0.92      0.91      1201\n",
      "         VBD       0.93      0.89      0.91      1341\n",
      "         VBG       0.91      0.77      0.83       623\n",
      "         VBN       0.83      0.84      0.83       970\n",
      "         VBP       0.85      0.85      0.85       561\n",
      "         VBZ       0.93      0.90      0.92       935\n",
      "         WDT       0.80      0.93      0.86       182\n",
      "          WP       1.00      1.00      1.00        85\n",
      "         WP$       1.00      1.00      1.00         5\n",
      "         WRB       0.94      0.98      0.96        98\n",
      "          ``       0.81      1.00      0.90       309\n",
      "\n",
      "    accuracy                           0.93     41439\n",
      "   macro avg       0.88      0.86      0.85     41439\n",
      "weighted avg       0.94      0.93      0.93     41439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "print (classification_report(true_pos_tags, predicted_pos_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6355220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy on the split test data set is 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "67817be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),               # gerund\n",
    "    (r'.*ed$', 'VBD'),                # past tense \n",
    "    (r'.*es$', 'VBZ'),                # verb    \n",
    "    (r'.*end$', 'VB'),\n",
    "    (r'^[A-Z].*$', 'NNP'),            # possessive nouns\n",
    "    (r'\\b\\w+s\\b', 'NNS'),             # plural nouns\n",
    "    (r'\\b\\w+NN\\b', 'NN'),             # singuular noun\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "    (r'.*', 'NN')                     # nouns\n",
    "]\n",
    " \n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cbe7ae40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(rule_based_tagger.tag(['cat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "64a3ae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "cntt = 0\n",
    "for sentence in test_set:\n",
    "    for word, _ in sentence:\n",
    "        if predicted_pos_tags[i] == tmp:\n",
    "            cntt += 1\n",
    "            predicted_pos_tags[i] = rule_based_tagger.tag([word])[0][1]\n",
    "        i += 1\n",
    "print(cntt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3b34fbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41439\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_pos_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ca3dbb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       1.00      1.00      1.00         6\n",
      "           $       0.81      1.00      0.90       311\n",
      "          ''       0.77      1.00      0.87       297\n",
      "           (       0.97      0.97      0.97        39\n",
      "           )       0.64      0.92      0.76        39\n",
      "           ,       0.98      1.00      0.99      2127\n",
      "           .       0.95      1.00      0.97      1767\n",
      "           :       0.99      0.99      0.99       203\n",
      "          CC       0.97      1.00      0.99      1054\n",
      "          CD       0.95      0.91      0.93      1599\n",
      "          DT       0.95      0.99      0.97      3576\n",
      "          EX       1.00      0.89      0.94        46\n",
      "          FW       1.00      0.10      0.18        10\n",
      "          IN       0.97      0.99      0.98      4399\n",
      "          JJ       0.90      0.86      0.88      2549\n",
      "         JJR       0.86      0.93      0.89       169\n",
      "         JJS       0.98      0.87      0.92        75\n",
      "          MD       0.92      1.00      0.96       376\n",
      "          NN       0.93      0.91      0.92      5942\n",
      "         NNP       0.93      0.92      0.92      3846\n",
      "        NNPS       0.91      0.52      0.67        82\n",
      "         NNS       0.92      0.89      0.90      2670\n",
      "         PDT       1.00      0.86      0.92         7\n",
      "         POS       0.88      0.97      0.93       350\n",
      "         PRP       0.87      0.99      0.93       759\n",
      "        PRP$       0.82      0.99      0.90       351\n",
      "          RB       0.91      0.91      0.91      1309\n",
      "         RBR       0.96      0.75      0.84        64\n",
      "         RBS       1.00      0.97      0.99        38\n",
      "          RP       0.00      0.00      0.00        16\n",
      "         SYM       0.00      0.00      0.00         1\n",
      "          TO       0.98      1.00      0.99      1050\n",
      "          UH       1.00      0.50      0.67         2\n",
      "          VB       0.89      0.92      0.91      1201\n",
      "         VBD       0.92      0.89      0.90      1341\n",
      "         VBG       0.88      0.77      0.82       623\n",
      "         VBN       0.83      0.84      0.83       970\n",
      "         VBP       0.85      0.85      0.85       561\n",
      "         VBZ       0.92      0.90      0.91       935\n",
      "         WDT       0.80      0.93      0.86       182\n",
      "          WP       1.00      1.00      1.00        85\n",
      "         WP$       1.00      1.00      1.00         5\n",
      "         WRB       0.94      0.98      0.96        98\n",
      "          ``       0.00      0.00      0.00       309\n",
      "\n",
      "    accuracy                           0.93     41439\n",
      "   macro avg       0.86      0.83      0.83     41439\n",
      "weighted avg       0.92      0.93      0.92     41439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(true_pos_tags, predicted_pos_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "032256a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'VBG', 'DT', 'NN', ',', 'VBD', 'PRP', 'MD', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NN', '.', 'CC', 'WRB', 'JJ', 'MD', 'NNS', 'VB', '.', '``', 'PRP', 'VBZ', 'RB', 'DT', 'JJ', ':', 'PRP', 'VBZ', 'TO', 'VB', 'DT', 'NN', 'IN', 'DT', 'NN', '.', \"''\", 'DT', 'NN', 'VBZ', 'JJ', 'NNP'] ['NNP', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'VBG', 'DT', 'NN', ',', 'VBD', 'PRP', 'MD', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NN', '.', 'CC', 'WRB', 'RB', 'MD', 'VB', 'NN', '.', 'NN', 'PRP', 'VBZ', 'RB', 'DT', 'NN', ':', 'PRP', 'VBZ', 'TO', 'VB', 'DT', 'NN', 'IN', 'DT', 'NN', '.', \"''\", 'DT', 'NN', 'VBZ', 'JJ', 'NNP'] ``\n"
     ]
    }
   ],
   "source": [
    "print(true_pos_tags[:50], predicted_pos_tags[:50],tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5bf48aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = open(\"test_data.txt\", \"r\")\n",
    "test_corpus = []\n",
    "\n",
    "for line in f_out:\n",
    "    line = line.strip()\n",
    "    if line == \"\":\n",
    "        continue\n",
    "    else:\n",
    "        test_corpus.append(line)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "b522b9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rockwell', 'International', 'Corp.', \"'s\", 'Tulsa']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3806f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_pos_tags=[]\n",
    "for word in test_corpus:\n",
    "    predicted_pos_tags += [tag for _, tag in HmmModel.tag([word])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "bbbd0bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5435 47377\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in predicted_pos_tags:\n",
    "    if i == predicted_pos_tags[0]:\n",
    "        cnt += 1\n",
    "print(cnt, len(predicted_pos_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "681291c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VBZ',\n",
       " '``',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'PRP',\n",
       " 'VBN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '``',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'TO',\n",
       " 'VB']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_pos_tags[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a5fcae26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_pos_tags[0] == '``'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "da4d7bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5435\n"
     ]
    }
   ],
   "source": [
    "cnttt = 0\n",
    "for i in predicted_pos_tags:\n",
    "    if i == tmp:\n",
    "        cnttt += 1\n",
    "print(cnttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4f3a420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for word in test_corpus:\n",
    "    if predicted_pos_tags[i] == tmp:\n",
    "        predicted_pos_tags[i] = rule_based_tagger.tag([word])[0][1]\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9aeed8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VBZ',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'VBD',\n",
       " 'PRP',\n",
       " 'VBN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'VBG',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'TO',\n",
       " 'VB']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_pos_tags[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2fffcdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_read = open(\"test_data_tagged.txt\", \"r\")\n",
    "data = []\n",
    "for line in f_read:\n",
    "    line = line.strip()\n",
    "    data.append(line)\n",
    "f_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6a10322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_write = open(\"test_data_tagged.txt\", \"w\")\n",
    "j = 0\n",
    "for line in data:\n",
    "    if line == '':\n",
    "        f_write.writelines(line + '\\n')\n",
    "        continue\n",
    "    else:\n",
    "        f_write.writelines(line + \" \" + predicted_pos_tags[j] + '\\n')\n",
    "    j += 1\n",
    "f_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "746b05b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 252\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in predicted_pos_tags:\n",
    "    if i == predicted_pos_tags[0]:\n",
    "        cnt += 1\n",
    "print(cnt, len(predicted_pos_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "68877a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'``'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d4b081d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = predicted_pos_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'``'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
